{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧮 Algebraic Language Model Exploration\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Master the algebraic operators for composing language models (+, *, |, &, ^, **, >>, <<, ~)\n",
    "- Understand how to combine n-gram models with different orders\n",
    "- Learn to apply projections for context transformation\n",
    "- Create sophisticated model compositions\n",
    "- Benchmark and visualize model performance\n",
    "\n",
    "## Prerequisites\n",
    "- Basic understanding of language models and n-grams\n",
    "- Python programming experience\n",
    "- Familiarity with probability distributions\n",
    "\n",
    "## Estimated Time: 45 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Part 1: Setup and Imports\n",
    "\n",
    "First, let's import all necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import time\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import our algebraic framework\n",
    "try:\n",
    "    from src.model_algebra import (\n",
    "        LanguageModel, NGramModel, MixtureModel,\n",
    "        WeightedModel, UnionModel, IntersectionModel,\n",
    "        ComplementModel, PowerModel, SequenceModel,\n",
    "        XORModel\n",
    "    )\n",
    "    print(\"✅ Successfully imported algebraic framework\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Import error: {e}\")\n",
    "    print(\"Using fallback implementations...\")\n",
    "    # Fallback definitions\n",
    "    from ngram_projections.models.base import LanguageModel\n",
    "    from ngram_projections.models.ngram import NGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Part 2: Understanding the Algebraic Operators\n",
    "\n",
    "Our framework provides 10+ algebraic operators for composing language models:\n",
    "\n",
    "| Operator | Symbol | Description | Example |\n",
    "|----------|--------|-------------|----------|\n",
    "| Addition | `+` | Equal-weight mixture | `model1 + model2` |\n",
    "| Multiplication | `*` | Weighted scaling | `0.3 * model` |\n",
    "| Union | `\\|` | Maximum probability | `model1 \\| model2` |\n",
    "| Intersection | `&` | Minimum probability | `model1 & model2` |\n",
    "| XOR | `^` | Exclusive or | `model1 ^ model2` |\n",
    "| Power | `**` | Model self-mixture | `model ** 2` |\n",
    "| Composition | `>>` | Sequential application | `model1 >> model2` |\n",
    "| Reverse Comp | `<<` | Reverse sequential | `model1 << model2` |\n",
    "| Complement | `~` | Invert probabilities | `~model` |\n",
    "| Projection | `@` | Apply transformation | `model @ projection` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive demonstration of operators\n",
    "def visualize_operator(op_name, op_symbol, description, example):\n",
    "    \"\"\"Create a visual card for an operator.\"\"\"\n",
    "    print(f\"╔{'═'*60}╗\")\n",
    "    print(f\"║ {op_name:20} {op_symbol:^10} {' '*28}║\")\n",
    "    print(f\"╠{'═'*60}╣\")\n",
    "    print(f\"║ {description:58} ║\")\n",
    "    print(f\"║ Example: {example:48} ║\")\n",
    "    print(f\"╚{'═'*60}╝\")\n",
    "\n",
    "# Display operator reference\n",
    "operators = [\n",
    "    (\"Addition\", \"+\", \"Equal-weight mixture of models\", \"model1 + model2\"),\n",
    "    (\"Multiplication\", \"*\", \"Scale model contribution\", \"0.3 * model\"),\n",
    "    (\"Union\", \"|\", \"Max probability per token\", \"model1 | model2\"),\n",
    "    (\"Intersection\", \"&\", \"Min probability per token\", \"model1 & model2\"),\n",
    "    (\"XOR\", \"^\", \"Exclusive combination\", \"model1 ^ model2\"),\n",
    "]\n",
    "\n",
    "for op in operators[:3]:  # Show first 3\n",
    "    visualize_operator(*op)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Part 3: Building and Training N-gram Models\n",
    "\n",
    "Let's create a diverse training corpus and build n-gram models of different orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training data\n",
    "training_corpus = {\n",
    "    \"scientific\": [\n",
    "        \"quantum computing leverages quantum mechanics for computation\",\n",
    "        \"neural networks learn hierarchical representations from data\",\n",
    "        \"machine learning algorithms optimize objective functions\",\n",
    "        \"deep learning models require substantial computational resources\",\n",
    "        \"artificial intelligence systems exhibit intelligent behavior\",\n",
    "    ],\n",
    "    \"literary\": [\n",
    "        \"the quick brown fox jumps over the lazy dog\",\n",
    "        \"in the garden roses bloom under moonlight\",\n",
    "        \"ancient wisdom speaks through forgotten manuscripts\",\n",
    "        \"the river flows gently through the valley\",\n",
    "        \"stars illuminate the darkness of night\",\n",
    "    ],\n",
    "    \"technical\": [\n",
    "        \"the server processes requests using multiple threads\",\n",
    "        \"database queries optimize through indexed columns\",\n",
    "        \"api endpoints handle authentication and authorization\",\n",
    "        \"cloud infrastructure scales automatically under load\",\n",
    "        \"microservices communicate through message queues\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten corpus\n",
    "all_texts = []\n",
    "for category, texts in training_corpus.items():\n",
    "    all_texts.extend(texts)\n",
    "    print(f\"📖 {category.capitalize()}: {len(texts)} documents\")\n",
    "\n",
    "print(f\"\\n📊 Total training documents: {len(all_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train n-gram models with different orders\n",
    "def train_ngram_models(texts, orders=[2, 3, 4]):\n",
    "    \"\"\"Train n-gram models of different orders.\"\"\"\n",
    "    models = {}\n",
    "    stats = {}\n",
    "    \n",
    "    for n in orders:\n",
    "        print(f\"\\n🔧 Training {n}-gram model...\")\n",
    "        model = NGramModel(n=n)\n",
    "        \n",
    "        # Train on all texts\n",
    "        total_ngrams = 0\n",
    "        for text in texts:\n",
    "            tokens = text.lower().split()\n",
    "            model.train(tokens)\n",
    "            total_ngrams += max(0, len(tokens) - n + 1)\n",
    "        \n",
    "        models[n] = model\n",
    "        stats[n] = {\n",
    "            'unique_ngrams': len(model.counts),\n",
    "            'total_ngrams': total_ngrams,\n",
    "            'avg_frequency': total_ngrams / len(model.counts) if model.counts else 0\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✅ Unique {n}-grams: {stats[n]['unique_ngrams']:,}\")\n",
    "        print(f\"  ✅ Total {n}-grams: {stats[n]['total_ngrams']:,}\")\n",
    "        print(f\"  ✅ Avg frequency: {stats[n]['avg_frequency']:.2f}\")\n",
    "    \n",
    "    return models, stats\n",
    "\n",
    "# Train models\n",
    "ngram_models, ngram_stats = train_ngram_models(all_texts, [2, 3, 4, 5])\n",
    "\n",
    "# Visualize statistics\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Unique n-grams\n",
    "orders = list(ngram_stats.keys())\n",
    "unique_counts = [ngram_stats[n]['unique_ngrams'] for n in orders]\n",
    "ax1.bar(orders, unique_counts, color='skyblue', edgecolor='navy')\n",
    "ax1.set_xlabel('N-gram Order')\n",
    "ax1.set_ylabel('Unique N-grams')\n",
    "ax1.set_title('Model Complexity')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average frequency\n",
    "avg_freq = [ngram_stats[n]['avg_frequency'] for n in orders]\n",
    "ax2.plot(orders, avg_freq, 'o-', color='coral', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('N-gram Order')\n",
    "ax2.set_ylabel('Average Frequency')\n",
    "ax2.set_title('Data Sparsity')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Part 4: Basic Algebraic Operations - Hands-on Experiments\n",
    "\n",
    "Now let's experiment with different algebraic operations and see how they affect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction explorer\n",
    "class PredictionExplorer:\n",
    "    \"\"\"Interactive tool for exploring model predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def predict_and_visualize(self, context, models_to_test=None, top_k=5):\n",
    "        \"\"\"Predict and visualize results from multiple models.\"\"\"\n",
    "        if models_to_test is None:\n",
    "            models_to_test = list(self.models.items())\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(models_to_test), figsize=(4*len(models_to_test), 5))\n",
    "        if len(models_to_test) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        print(f\"🔍 Context: '{' '.join(context)}'\\n\")\n",
    "        \n",
    "        for ax, (name, model) in zip(axes, models_to_test):\n",
    "            # Get predictions\n",
    "            preds = model.predict(context)\n",
    "            \n",
    "            if preds:\n",
    "                # Get top k predictions\n",
    "                top_preds = sorted(preds.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "                tokens = [t for t, _ in top_preds]\n",
    "                probs = [p for _, p in top_preds]\n",
    "                \n",
    "                # Visualize\n",
    "                bars = ax.bar(range(len(tokens)), probs, color='steelblue', edgecolor='navy')\n",
    "                ax.set_xticks(range(len(tokens)))\n",
    "                ax.set_xticklabels(tokens, rotation=45, ha='right')\n",
    "                ax.set_ylabel('Probability')\n",
    "                ax.set_title(name, fontweight='bold')\n",
    "                ax.set_ylim([0, max(probs) * 1.2 if probs else 1])\n",
    "                \n",
    "                # Add value labels on bars\n",
    "                for bar, prob in zip(bars, probs):\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{prob:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "                \n",
    "                # Print top prediction\n",
    "                print(f\"  {name}: '{tokens[0]}' ({probs[0]:.3f})\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No predictions', ha='center', va='center', \n",
    "                       transform=ax.transAxes)\n",
    "                ax.set_title(name, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle(f\"Model Predictions for: '{' '.join(context)}'\", fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create explorer\n",
    "explorer = PredictionExplorer(ngram_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Pure n-gram models\n",
    "print(\"🔬 Experiment 1: Comparing N-gram Orders\\n\")\n",
    "print(\"How does n-gram order affect predictions?\\n\")\n",
    "\n",
    "test_context = [\"machine\", \"learning\"]\n",
    "\n",
    "models_to_compare = [\n",
    "    (\"2-gram\", ngram_models[2]),\n",
    "    (\"3-gram\", ngram_models[3]),\n",
    "    (\"4-gram\", ngram_models[4]),\n",
    "]\n",
    "\n",
    "explorer.predict_and_visualize(test_context, models_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Model Addition (Mixture)\n",
    "print(\"🔬 Experiment 2: Model Addition (Equal Mixture)\\n\")\n",
    "print(\"What happens when we combine models with + operator?\\n\")\n",
    "\n",
    "# Create mixtures\n",
    "mixture_2_3 = ngram_models[2] + ngram_models[3]\n",
    "mixture_3_4 = ngram_models[3] + ngram_models[4]\n",
    "mixture_all = ngram_models[2] + ngram_models[3] + ngram_models[4]\n",
    "\n",
    "models_to_compare = [\n",
    "    (\"2-gram\", ngram_models[2]),\n",
    "    (\"3-gram\", ngram_models[3]),\n",
    "    (\"2+3 mixture\", mixture_2_3),\n",
    "    (\"2+3+4 mixture\", mixture_all),\n",
    "]\n",
    "\n",
    "explorer.predict_and_visualize(test_context, models_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Weighted Mixtures\n",
    "print(\"🔬 Experiment 3: Weighted Mixtures\\n\")\n",
    "print(\"How do weights affect the mixture?\\n\")\n",
    "\n",
    "# Try different weight configurations\n",
    "weight_configs = [\n",
    "    (0.9, 0.1, \"90% 2-gram + 10% 3-gram\"),\n",
    "    (0.5, 0.5, \"50% 2-gram + 50% 3-gram\"),\n",
    "    (0.1, 0.9, \"10% 2-gram + 90% 3-gram\"),\n",
    "]\n",
    "\n",
    "weighted_models = []\n",
    "for w1, w2, name in weight_configs:\n",
    "    model = w1 * ngram_models[2] + w2 * ngram_models[3]\n",
    "    weighted_models.append((name, model))\n",
    "\n",
    "# Add pure models for reference\n",
    "weighted_models.insert(0, (\"Pure 2-gram\", ngram_models[2]))\n",
    "weighted_models.append((\"Pure 3-gram\", ngram_models[3]))\n",
    "\n",
    "# Visualize\n",
    "test_context = [\"neural\", \"networks\"]\n",
    "explorer.predict_and_visualize(test_context, weighted_models[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎛️ Part 5: Advanced Operators - Interactive Playground\n",
    "\n",
    "Let's explore the more advanced operators: Union (|), Intersection (&), XOR (^), and Power (**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized models for demonstration\n",
    "scientific_model = NGramModel(n=3)\n",
    "literary_model = NGramModel(n=3)\n",
    "\n",
    "# Train on specialized corpora\n",
    "for text in training_corpus[\"scientific\"]:\n",
    "    scientific_model.train(text.lower().split())\n",
    "\n",
    "for text in training_corpus[\"literary\"]:\n",
    "    literary_model.train(text.lower().split())\n",
    "\n",
    "print(\"✅ Trained specialized models:\")\n",
    "print(f\"  Scientific model: {len(scientific_model.counts)} n-grams\")\n",
    "print(f\"  Literary model: {len(literary_model.counts)} n-grams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive operator comparison\n",
    "def compare_operators(model1, model2, context, operators=['|', '&', '^']):\n",
    "    \"\"\"Compare different operators on two models.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Get individual predictions\n",
    "    pred1 = model1.predict(context)\n",
    "    pred2 = model2.predict(context)\n",
    "    \n",
    "    # Apply operators\n",
    "    if '|' in operators:  # Union\n",
    "        union_model = model1 | model2\n",
    "        results['Union (|)'] = union_model.predict(context)\n",
    "    \n",
    "    if '&' in operators:  # Intersection\n",
    "        inter_model = model1 & model2\n",
    "        results['Intersection (&)'] = inter_model.predict(context)\n",
    "    \n",
    "    if '^' in operators:  # XOR\n",
    "        xor_model = model1 ^ model2\n",
    "        results['XOR (^)'] = xor_model.predict(context)\n",
    "    \n",
    "    if '+' in operators:  # Addition\n",
    "        add_model = model1 + model2\n",
    "        results['Addition (+)'] = add_model.predict(context)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot individual models\n",
    "    for i, (name, pred) in enumerate([('Scientific', pred1), ('Literary', pred2)]):\n",
    "        if pred:\n",
    "            tokens = list(pred.keys())[:5]\n",
    "            probs = [pred[t] for t in tokens]\n",
    "            axes[i].bar(tokens, probs, color='lightblue' if i == 0 else 'lightcoral')\n",
    "            axes[i].set_title(f'{name} Model', fontweight='bold')\n",
    "            axes[i].set_ylabel('Probability')\n",
    "            axes[i].set_xticklabels(tokens, rotation=45)\n",
    "    \n",
    "    # Plot operator results\n",
    "    colors = ['green', 'orange', 'purple', 'red']\n",
    "    for i, (op_name, pred) in enumerate(results.items()):\n",
    "        ax = axes[i + 2]\n",
    "        if pred:\n",
    "            tokens = list(pred.keys())[:5]\n",
    "            probs = [pred[t] for t in tokens]\n",
    "            ax.bar(tokens, probs, color=colors[i % len(colors)])\n",
    "            ax.set_title(f'{op_name}', fontweight='bold')\n",
    "            ax.set_ylabel('Probability')\n",
    "            ax.set_xticklabels(tokens, rotation=45)\n",
    "    \n",
    "    # Hide unused subplot\n",
    "    if len(results) < 4:\n",
    "        axes[-1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Operator Comparison | Context: '{' '.join(context)}'\", \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test advanced operators\n",
    "test_context = [\"the\", \"system\"]\n",
    "print(\"🔬 Advanced Operator Comparison\\n\")\n",
    "results = compare_operators(scientific_model, literary_model, test_context, \n",
    "                           operators=['|', '&', '^', '+'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Part 6: Context Transformations and Projections\n",
    "\n",
    "Projections transform the context before feeding it to the model. Let's implement and test various projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement custom projections\n",
    "class Projection:\n",
    "    \"\"\"Base class for context projections.\"\"\"\n",
    "    def project(self, context: List[str]) -> List[str]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class RecencyProjection(Projection):\n",
    "    \"\"\"Keep only recent tokens.\"\"\"\n",
    "    def __init__(self, max_length=3):\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def project(self, context: List[str]) -> List[str]:\n",
    "        return context[-self.max_length:]\n",
    "\n",
    "class LowercaseProjection(Projection):\n",
    "    \"\"\"Convert to lowercase.\"\"\"\n",
    "    def project(self, context: List[str]) -> List[str]:\n",
    "        return [t.lower() for t in context]\n",
    "\n",
    "class StopwordFilterProjection(Projection):\n",
    "    \"\"\"Remove common stopwords.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been'}\n",
    "    \n",
    "    def project(self, context: List[str]) -> List[str]:\n",
    "        return [t for t in context if t.lower() not in self.stopwords]\n",
    "\n",
    "class KeywordBoostProjection(Projection):\n",
    "    \"\"\"Duplicate important keywords.\"\"\"\n",
    "    def __init__(self, keywords):\n",
    "        self.keywords = set(keywords)\n",
    "    \n",
    "    def project(self, context: List[str]) -> List[str]:\n",
    "        result = []\n",
    "        for token in context:\n",
    "            result.append(token)\n",
    "            if token.lower() in self.keywords:\n",
    "                result.append(token)  # Duplicate keyword\n",
    "        return result\n",
    "\n",
    "# Create projections\n",
    "recency_proj = RecencyProjection(max_length=3)\n",
    "lowercase_proj = LowercaseProjection()\n",
    "stopword_proj = StopwordFilterProjection()\n",
    "keyword_proj = KeywordBoostProjection(['quantum', 'neural', 'learning'])\n",
    "\n",
    "print(\"✅ Created 4 different projection types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize projection effects\n",
    "def visualize_projections(context, projections):\n",
    "    \"\"\"Show how different projections transform context.\"\"\"\n",
    "    \n",
    "    print(\"🔄 Context Transformation Visualization\\n\")\n",
    "    print(f\"Original context: {context}\")\n",
    "    print(f\"Length: {len(context)}\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = []\n",
    "    for name, proj in projections:\n",
    "        transformed = proj.project(context)\n",
    "        results.append((name, transformed))\n",
    "        \n",
    "        print(f\"\\n📐 {name}:\")\n",
    "        print(f\"  Result: {transformed}\")\n",
    "        print(f\"  Length: {len(transformed)}\")\n",
    "        \n",
    "        # Show changes\n",
    "        if len(transformed) < len(context):\n",
    "            print(f\"  ⬇️ Reduced by {len(context) - len(transformed)} tokens\")\n",
    "        elif len(transformed) > len(context):\n",
    "            print(f\"  ⬆️ Increased by {len(transformed) - len(context)} tokens\")\n",
    "        else:\n",
    "            print(f\"  ↔️ Same length\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test projections\n",
    "test_context = [\"The\", \"neural\", \"network\", \"learns\", \"from\", \"the\", \"training\", \"data\"]\n",
    "\n",
    "projections = [\n",
    "    (\"Recency (last 3)\", recency_proj),\n",
    "    (\"Lowercase\", lowercase_proj),\n",
    "    (\"Stopword Filter\", stopword_proj),\n",
    "    (\"Keyword Boost\", keyword_proj),\n",
    "]\n",
    "\n",
    "results = visualize_projections(test_context, projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply projections to models\n",
    "class ProjectedModel(LanguageModel):\n",
    "    \"\"\"Model with projection applied.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, projection):\n",
    "        self.model = model\n",
    "        self.projection = projection\n",
    "    \n",
    "    def predict(self, context):\n",
    "        transformed = self.projection.project(context)\n",
    "        return self.model.predict(transformed)\n",
    "    \n",
    "    def train(self, tokens):\n",
    "        self.model.train(tokens)\n",
    "\n",
    "# Create projected models\n",
    "base_model = ngram_models[3]\n",
    "recency_model = ProjectedModel(base_model, recency_proj)\n",
    "filtered_model = ProjectedModel(base_model, stopword_proj)\n",
    "\n",
    "# Compare predictions\n",
    "test_context = [\"the\", \"machine\", \"learning\", \"algorithm\", \"processes\"]\n",
    "\n",
    "print(\"🔬 Projection Effects on Predictions\\n\")\n",
    "\n",
    "models_to_test = [\n",
    "    (\"No Projection\", base_model),\n",
    "    (\"Recency Projection\", recency_model),\n",
    "    (\"Stopword Filtered\", filtered_model),\n",
    "]\n",
    "\n",
    "for name, model in models_to_test:\n",
    "    preds = model.predict(test_context)\n",
    "    if preds:\n",
    "        top_pred = max(preds.items(), key=lambda x: x[1])\n",
    "        print(f\"{name:20} → Top: '{top_pred[0]}' ({top_pred[1]:.3f})\")\n",
    "    else:\n",
    "        print(f\"{name:20} → No predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Part 7: Performance Benchmarking\n",
    "\n",
    "Let's benchmark different model configurations to understand their performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive benchmarking suite\n",
    "class ModelBenchmark:\n",
    "    \"\"\"Benchmark model performance.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "    \n",
    "    def benchmark(self, models, test_contexts, runs=100):\n",
    "        \"\"\"Run performance benchmarks.\"\"\"\n",
    "        \n",
    "        for name, model in models:\n",
    "            times = []\n",
    "            memory = []\n",
    "            \n",
    "            for _ in range(runs):\n",
    "                # Time prediction\n",
    "                start = time.time()\n",
    "                for context in test_contexts:\n",
    "                    _ = model.predict(context)\n",
    "                elapsed = time.time() - start\n",
    "                times.append(elapsed * 1000)  # Convert to ms\n",
    "            \n",
    "            self.results[name] = {\n",
    "                'mean_time': np.mean(times),\n",
    "                'std_time': np.std(times),\n",
    "                'min_time': np.min(times),\n",
    "                'max_time': np.max(times),\n",
    "            }\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize benchmark results.\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to visualize\")\n",
    "            return\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Bar chart of mean times\n",
    "        names = list(self.results.keys())\n",
    "        means = [self.results[n]['mean_time'] for n in names]\n",
    "        stds = [self.results[n]['std_time'] for n in names]\n",
    "        \n",
    "        colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(names)))\n",
    "        bars = ax1.bar(range(len(names)), means, yerr=stds, \n",
    "                      color=colors, capsize=5, edgecolor='black')\n",
    "        ax1.set_xticks(range(len(names)))\n",
    "        ax1.set_xticklabels(names, rotation=45, ha='right')\n",
    "        ax1.set_ylabel('Time (ms)')\n",
    "        ax1.set_title('Model Latency Comparison', fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, mean in zip(bars, means):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{mean:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Box plot for distribution\n",
    "        data_for_box = []\n",
    "        labels_for_box = []\n",
    "        for name in names:\n",
    "            # Simulate distribution\n",
    "            mean = self.results[name]['mean_time']\n",
    "            std = self.results[name]['std_time']\n",
    "            samples = np.random.normal(mean, std, 100)\n",
    "            data_for_box.append(samples)\n",
    "            labels_for_box.append(name)\n",
    "        \n",
    "        bp = ax2.boxplot(data_for_box, labels=labels_for_box, patch_artist=True)\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        ax2.set_ylabel('Time (ms)')\n",
    "        ax2.set_title('Latency Distribution', fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xticklabels(labels_for_box, rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary table\n",
    "        print(\"\\n📊 Performance Summary\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"{'Model':<25} {'Mean (ms)':<12} {'Std (ms)':<12} {'Min (ms)':<12} {'Max (ms)':<12}\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        for name in names:\n",
    "            r = self.results[name]\n",
    "            print(f\"{name:<25} {r['mean_time']:<12.3f} {r['std_time']:<12.3f} \"\n",
    "                  f\"{r['min_time']:<12.3f} {r['max_time']:<12.3f}\")\n",
    "\n",
    "# Run benchmarks\n",
    "benchmark = ModelBenchmark()\n",
    "\n",
    "# Models to benchmark\n",
    "models_to_benchmark = [\n",
    "    (\"2-gram\", ngram_models[2]),\n",
    "    (\"3-gram\", ngram_models[3]),\n",
    "    (\"4-gram\", ngram_models[4]),\n",
    "    (\"2+3 mixture\", ngram_models[2] + ngram_models[3]),\n",
    "    (\"Weighted (0.3*2 + 0.7*3)\", 0.3 * ngram_models[2] + 0.7 * ngram_models[3]),\n",
    "    (\"Union (2|3)\", ngram_models[2] | ngram_models[3]),\n",
    "]\n",
    "\n",
    "# Test contexts\n",
    "test_contexts = [\n",
    "    [\"the\", \"model\"],\n",
    "    [\"neural\", \"network\", \"learns\"],\n",
    "    [\"machine\", \"learning\", \"algorithm\", \"processes\"],\n",
    "]\n",
    "\n",
    "print(\"⏱️ Running performance benchmarks...\")\n",
    "results = benchmark.benchmark(models_to_benchmark, test_contexts, runs=50)\n",
    "benchmark.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Part 8: Practical Application - Building a Domain-Specific Model\n",
    "\n",
    "Let's build a sophisticated model for a specific use case using our algebraic framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a technical documentation assistant\n",
    "class TechnicalAssistant:\n",
    "    \"\"\"Domain-specific model using algebraic composition.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Train specialized models\n",
    "        self.api_model = NGramModel(n=3)\n",
    "        self.error_model = NGramModel(n=3)\n",
    "        self.general_model = NGramModel(n=2)\n",
    "        \n",
    "        # Training data\n",
    "        api_docs = [\n",
    "            \"the api endpoint returns json response\",\n",
    "            \"authentication token must be included in headers\",\n",
    "            \"rate limiting prevents excessive requests\",\n",
    "            \"the rest api uses standard http methods\",\n",
    "        ]\n",
    "        \n",
    "        error_docs = [\n",
    "            \"error code 404 indicates resource not found\",\n",
    "            \"internal server error requires investigation\",\n",
    "            \"timeout errors occur under heavy load\",\n",
    "            \"validation error means invalid input data\",\n",
    "        ]\n",
    "        \n",
    "        # Train models\n",
    "        for doc in api_docs:\n",
    "            self.api_model.train(doc.split())\n",
    "        \n",
    "        for doc in error_docs:\n",
    "            self.error_model.train(doc.split())\n",
    "        \n",
    "        for doc in api_docs + error_docs:\n",
    "            self.general_model.train(doc.split())\n",
    "        \n",
    "        # Create composite model\n",
    "        self.model = self._build_composite_model()\n",
    "    \n",
    "    def _build_composite_model(self):\n",
    "        \"\"\"Build sophisticated composite model.\"\"\"\n",
    "        # API-focused mixture\n",
    "        api_mixture = 0.7 * self.api_model + 0.3 * self.general_model\n",
    "        \n",
    "        # Error-focused mixture\n",
    "        error_mixture = 0.8 * self.error_model + 0.2 * self.general_model\n",
    "        \n",
    "        # Combined with union for fallback\n",
    "        combined = (0.5 * api_mixture + 0.5 * error_mixture) | self.general_model\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def complete(self, context, mode='auto'):\n",
    "        \"\"\"Get completions with mode selection.\"\"\"\n",
    "        \n",
    "        # Auto-detect mode from context\n",
    "        if mode == 'auto':\n",
    "            context_str = ' '.join(context).lower()\n",
    "            if 'error' in context_str or 'exception' in context_str:\n",
    "                mode = 'error'\n",
    "            elif 'api' in context_str or 'endpoint' in context_str:\n",
    "                mode = 'api'\n",
    "            else:\n",
    "                mode = 'general'\n",
    "        \n",
    "        # Select appropriate model\n",
    "        if mode == 'api':\n",
    "            model = self.api_model\n",
    "        elif mode == 'error':\n",
    "            model = self.error_model\n",
    "        else:\n",
    "            model = self.model  # Use composite\n",
    "        \n",
    "        return model.predict(context), mode\n",
    "\n",
    "# Create assistant\n",
    "assistant = TechnicalAssistant()\n",
    "\n",
    "# Test different contexts\n",
    "test_cases = [\n",
    "    ([\"the\", \"api\", \"endpoint\"], 'auto'),\n",
    "    ([\"error\", \"code\"], 'auto'),\n",
    "    ([\"the\", \"server\"], 'auto'),\n",
    "    ([\"authentication\", \"token\"], 'api'),\n",
    "    ([\"timeout\", \"errors\"], 'error'),\n",
    "]\n",
    "\n",
    "print(\"🤖 Technical Documentation Assistant\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for context, mode_hint in test_cases:\n",
    "    preds, detected_mode = assistant.complete(context, mode_hint)\n",
    "    \n",
    "    print(f\"\\nContext: {' '.join(context)}\")\n",
    "    print(f\"Mode: {detected_mode}\")\n",
    "    \n",
    "    if preds:\n",
    "        top_3 = sorted(preds.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        print(\"Suggestions:\")\n",
    "        for token, prob in top_3:\n",
    "            print(f\"  • {token} ({prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Part 9: Model Introspection and Analysis\n",
    "\n",
    "Let's analyze how our algebraic operations affect model behavior internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze probability distributions\n",
    "def analyze_distribution(model, context, name=\"Model\"):\n",
    "    \"\"\"Analyze the probability distribution of a model.\"\"\"\n",
    "    \n",
    "    preds = model.predict(context)\n",
    "    \n",
    "    if not preds:\n",
    "        print(f\"No predictions for {name}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate statistics\n",
    "    probs = list(preds.values())\n",
    "    stats = {\n",
    "        'num_tokens': len(preds),\n",
    "        'max_prob': max(probs),\n",
    "        'min_prob': min(probs),\n",
    "        'mean_prob': np.mean(probs),\n",
    "        'std_prob': np.std(probs),\n",
    "        'entropy': -sum(p * np.log2(p) if p > 0 else 0 for p in probs),\n",
    "        'top_token': max(preds.items(), key=lambda x: x[1])[0],\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Compare distributions\n",
    "def compare_distributions(models, context):\n",
    "    \"\"\"Compare probability distributions across models.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    stats_list = []\n",
    "    \n",
    "    for i, (name, model) in enumerate(models[:6]):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        preds = model.predict(context)\n",
    "        stats = analyze_distribution(model, context, name)\n",
    "        \n",
    "        if preds and stats:\n",
    "            stats_list.append((name, stats))\n",
    "            \n",
    "            # Plot distribution\n",
    "            tokens = list(preds.keys())[:10]\n",
    "            probs = [preds[t] for t in tokens]\n",
    "            \n",
    "            bars = ax.bar(range(len(tokens)), probs, color='steelblue')\n",
    "            ax.set_xticks(range(len(tokens)))\n",
    "            ax.set_xticklabels(tokens, rotation=45, ha='right', fontsize=8)\n",
    "            ax.set_ylabel('Probability')\n",
    "            ax.set_title(f\"{name}\\nEntropy: {stats['entropy']:.2f}\", fontsize=10)\n",
    "            \n",
    "            # Add entropy line\n",
    "            ax.axhline(y=1/len(preds), color='red', linestyle='--', \n",
    "                      alpha=0.5, label='Uniform')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'No predictions', ha='center', va='center',\n",
    "                   transform=ax.transAxes)\n",
    "            ax.set_title(name)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for i in range(len(models), 6):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Distribution Analysis | Context: '{' '.join(context)}'\", \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics table\n",
    "    if stats_list:\n",
    "        print(\"\\n📊 Distribution Statistics\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{'Model':<20} {'Entropy':<10} {'Max Prob':<10} {'Top Token':<15} {'# Tokens':<10}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        for name, stats in stats_list:\n",
    "            print(f\"{name:<20} {stats['entropy']:<10.3f} {stats['max_prob']:<10.3f} \"\n",
    "                  f\"{stats['top_token']:<15} {stats['num_tokens']:<10}\")\n",
    "\n",
    "# Test distribution analysis\n",
    "context = [\"machine\", \"learning\"]\n",
    "\n",
    "models_to_analyze = [\n",
    "    (\"2-gram\", ngram_models[2]),\n",
    "    (\"3-gram\", ngram_models[3]),\n",
    "    (\"Equal Mix\", ngram_models[2] + ngram_models[3]),\n",
    "    (\"Weighted Mix\", 0.2 * ngram_models[2] + 0.8 * ngram_models[3]),\n",
    "    (\"Union\", ngram_models[2] | ngram_models[3]),\n",
    "    (\"Intersection\", ngram_models[2] & ngram_models[3]),\n",
    "]\n",
    "\n",
    "compare_distributions(models_to_analyze, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Part 10: Advanced Techniques and Best Practices\n",
    "\n",
    "Let's explore advanced techniques for optimal model composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices demonstration\n",
    "print(\"🎓 Best Practices for Algebraic Model Composition\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Hierarchical Composition\n",
    "print(\"\\n1️⃣ Hierarchical Composition\")\n",
    "print(\"-\"*40)\n",
    "print(\"Build complex models from simple components:\")\n",
    "\n",
    "# Base models\n",
    "base_2 = ngram_models[2]\n",
    "base_3 = ngram_models[3]\n",
    "base_4 = ngram_models[4]\n",
    "\n",
    "# Level 1: Simple mixtures\n",
    "level1_a = 0.6 * base_2 + 0.4 * base_3\n",
    "level1_b = 0.3 * base_3 + 0.7 * base_4\n",
    "\n",
    "# Level 2: Combine mixtures\n",
    "level2 = (level1_a | level1_b)  # Union for robustness\n",
    "\n",
    "# Level 3: Final composition\n",
    "final = 0.8 * level2 + 0.2 * base_2  # Add fallback\n",
    "\n",
    "print(\"  Base → Mixtures → Union → Final\")\n",
    "print(f\"  Complexity: {3} levels\")\n",
    "\n",
    "# 2. Dynamic Weight Adjustment\n",
    "print(\"\\n2️⃣ Dynamic Weight Adjustment\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "def dynamic_mixture(models, context):\n",
    "    \"\"\"Adjust weights based on context length.\"\"\"\n",
    "    context_len = len(context)\n",
    "    \n",
    "    if context_len < 2:\n",
    "        # Short context: prefer lower-order\n",
    "        weights = [0.8, 0.2, 0.0]\n",
    "    elif context_len < 4:\n",
    "        # Medium context: balanced\n",
    "        weights = [0.3, 0.5, 0.2]\n",
    "    else:\n",
    "        # Long context: prefer higher-order\n",
    "        weights = [0.1, 0.3, 0.6]\n",
    "    \n",
    "    # Create weighted mixture\n",
    "    result = None\n",
    "    for model, weight in zip(models, weights):\n",
    "        if weight > 0:\n",
    "            weighted = weight * model\n",
    "            result = weighted if result is None else result + weighted\n",
    "    \n",
    "    return result, weights\n",
    "\n",
    "# Test dynamic adjustment\n",
    "test_contexts = [\n",
    "    [\"the\"],\n",
    "    [\"machine\", \"learning\"],\n",
    "    [\"the\", \"neural\", \"network\", \"model\", \"learns\"],\n",
    "]\n",
    "\n",
    "models = [base_2, base_3, base_4]\n",
    "\n",
    "for ctx in test_contexts:\n",
    "    mixture, weights = dynamic_mixture(models, ctx)\n",
    "    print(f\"  Context length {len(ctx)}: weights = {weights}\")\n",
    "\n",
    "# 3. Ensemble Strategies\n",
    "print(\"\\n3️⃣ Ensemble Strategies\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Voting ensemble\n",
    "def voting_ensemble(models, context, threshold=0.1):\n",
    "    \"\"\"Combine models through voting.\"\"\"\n",
    "    votes = Counter()\n",
    "    \n",
    "    for model in models:\n",
    "        preds = model.predict(context)\n",
    "        if preds:\n",
    "            # Vote for tokens above threshold\n",
    "            for token, prob in preds.items():\n",
    "                if prob > threshold:\n",
    "                    votes[token] += 1\n",
    "    \n",
    "    # Normalize to probabilities\n",
    "    total = sum(votes.values())\n",
    "    if total > 0:\n",
    "        return {token: count/total for token, count in votes.items()}\n",
    "    return {}\n",
    "\n",
    "# Test voting\n",
    "context = [\"neural\", \"network\"]\n",
    "ensemble_pred = voting_ensemble([base_2, base_3, base_4], context)\n",
    "\n",
    "if ensemble_pred:\n",
    "    top_token = max(ensemble_pred.items(), key=lambda x: x[1])\n",
    "    print(f\"  Voting ensemble prediction: '{top_token[0]}' ({top_token[1]:.3f})\")\n",
    "\n",
    "# 4. Performance Optimization\n",
    "print(\"\\n4️⃣ Performance Optimization Tips\")\n",
    "print(\"-\"*40)\n",
    "print(\"  • Cache frequently used mixtures\")\n",
    "print(\"  • Use Union (|) for parallel search\")\n",
    "print(\"  • Apply projections to reduce context size\")\n",
    "print(\"  • Precompute static model combinations\")\n",
    "print(\"  • Profile to identify bottlenecks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Part 11: Your Turn - Interactive Playground\n",
    "\n",
    "Use this section to experiment with your own model compositions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive model builder\n",
    "print(\"🛠️ Interactive Model Builder\\n\")\n",
    "print(\"Build your own model using algebraic operations!\\n\")\n",
    "print(\"Available base models: base_2, base_3, base_4\")\n",
    "print(\"Available operators: +, *, |, &, ^\\n\")\n",
    "\n",
    "# Example compositions to try\n",
    "examples = [\n",
    "    \"0.5 * base_2 + 0.5 * base_3\",\n",
    "    \"(base_2 | base_3) & base_4\",\n",
    "    \"0.3 * base_2 + 0.4 * base_3 + 0.3 * base_4\",\n",
    "    \"base_2 ^ base_3\",\n",
    "]\n",
    "\n",
    "print(\"Example compositions to try:\")\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"  {i}. {example}\")\n",
    "\n",
    "# TODO: Modify this section to create your own compositions\n",
    "# Your composition here:\n",
    "my_model = 0.4 * base_2 + 0.6 * base_3  # Change this!\n",
    "\n",
    "# Test your model\n",
    "test_contexts = [\n",
    "    [\"machine\", \"learning\"],\n",
    "    [\"neural\", \"network\"],\n",
    "    [\"the\", \"model\"],\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing your model:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for context in test_contexts:\n",
    "    preds = my_model.predict(context)\n",
    "    if preds:\n",
    "        top = max(preds.items(), key=lambda x: x[1])\n",
    "        print(f\"Context: {' '.join(context):20} → '{top[0]}' ({top[1]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Summary and Key Takeaways\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Algebraic Operators**: \n",
    "   - Addition (+) for equal mixtures\n",
    "   - Multiplication (*) for weighted scaling\n",
    "   - Union (|) for maximum/fallback behavior\n",
    "   - Intersection (&) for consensus\n",
    "   - XOR (^) for exclusive combination\n",
    "\n",
    "2. **Projections**:\n",
    "   - Transform context before model processing\n",
    "   - Can filter, boost, or reshape input\n",
    "   - Composable with >> operator\n",
    "\n",
    "3. **Performance**:\n",
    "   - Simple models are fast but less accurate\n",
    "   - Complex compositions trade speed for quality\n",
    "   - Caching and optimization are crucial\n",
    "\n",
    "4. **Best Practices**:\n",
    "   - Start simple, add complexity gradually\n",
    "   - Use hierarchical composition\n",
    "   - Consider dynamic weight adjustment\n",
    "   - Profile and optimize bottlenecks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Try the **lightweight_grounding_demo.ipynb** to see real-world applications\n",
    "2. Explore **unified_algebra.ipynb** for advanced theoretical concepts\n",
    "3. Build your own domain-specific models\n",
    "4. Experiment with custom projections\n",
    "5. Benchmark against traditional approaches\n",
    "\n",
    "### 🚀 Challenge Yourself\n",
    "\n",
    "Can you create a model that:\n",
    "- Adapts to context length dynamically?\n",
    "- Combines 5+ different n-gram orders efficiently?\n",
    "- Uses projections to improve accuracy by 20%?\n",
    "- Achieves <1ms latency for predictions?\n",
    "\n",
    "Happy experimenting! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}